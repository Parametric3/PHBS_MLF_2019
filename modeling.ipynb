{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading files\n",
    "excelFile1 = r'user_item_pair_train_ZP.xlsx'\n",
    "excelFile2 = r'user_item_pair_train_XCQ.xlsx'\n",
    "excelFile3 = r'user_item_pair_test_ZP.xlsx'\n",
    "excelFile4 = r'user_item_pair_test_XCQ.xlsx'\n",
    "df1 = pd.DataFrame(pd.read_excel(excelFile1))\n",
    "df2 = pd.DataFrame(pd.read_excel(excelFile2))\n",
    "df3 = pd.DataFrame(pd.read_excel(excelFile3))\n",
    "df4 = pd.DataFrame(pd.read_excel(excelFile4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 47)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#over&down sampling\n",
    "data1 = df[df['label'] == 1]  # 将少数类别的样本（购买）放在data1\n",
    "data0 = df[df['label'] == 0]  # 将多数类别的样本（没有购买）放在data0\n",
    "oversample = data1.sample(frac=6, replace=True)\n",
    "downsample = data0.sample(frac=0.3, replace=True)\n",
    "df = pd.merge(data1,data0,left_index=True,right_index=True,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label\n",
    "X_train = df.drop(columns=['label','user_id','item_id','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#GS之后跑\n",
    "C_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = {'penalty': ['l1'],\n",
    "              'C': C_range}\n",
    "gs_lr = GridSearchCV(estimator=LogisticRegression(random_state=1),\n",
    "                 param_grid=param_grid,\n",
    "                 scoring='accuracy', \n",
    "                 refit=True,\n",
    "                 cv=10,\n",
    "                 n_jobs=-1)\n",
    "gs_lr = gs_lr.fit(X, y)\n",
    "print(gs_lr.best_score_)\n",
    "print(gs_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1',C=0.01)\n",
    "lr = lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))\n",
    "lr.coef_[lr.coef_!=0].shape # check the number of the features with non-zero weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-3dd26430cf36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "plot.pca(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-75b40744a750>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#PCA+LR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_test_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#PCA+LR\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X)\n",
    "X_test_pca = pca.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=10)#explain 90% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = {'penalty': ['l2'],\n",
    "              'C': C_range,\n",
    "              'solver': ['lbfgs']}\n",
    "gs_lr = GridSearchCV(estimator=LogisticRegression(random_state=1),\n",
    "                 param_grid=param_grid,\n",
    "                 scoring='accuracy', \n",
    "                 refit=True,\n",
    "                 cv=10,\n",
    "                 n_jobs=-1)\n",
    "gs_lr = gs_lr.fit(X_train_pca, y_train)\n",
    "print(gs_lr.best_score_)\n",
    "print(gs_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM(to be run if have time)\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'svc__C': param_range, \n",
    "               'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, \n",
    "               'svc__gamma': param_range, \n",
    "               'svc__kernel': ['rbf']}]\n",
    "\n",
    "gs_svc = GridSearchCV(estimator=pipe_svc, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs_svc = gs_svc.fit(X_train, y_train)\n",
    "print(gs_svc.best_score_)\n",
    "print(gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=100)\n",
    "clf1.fit(X,y)\n",
    "clf3 = LogisticRegression().fit(X, y)\n",
    "print clf2.classes_\n",
    "f1=open(\"test_data_9feature.txt\")\n",
    "data1=np.loadtxt(f1)\n",
    "X_new=data1[:,:]\n",
    "print 'testing data is ok'\n",
    "result=clf2.predict_proba(X_new)\n",
    "print 'output result'\n",
    "print result\n",
    "f_result=open('result9.txt','w')\n",
    "for i in range(0,len(result)):\n",
    "    f_result.write(str(result[i])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "#Define functions for valuation\n",
    "get_learning_curve\n",
    "def get_learning_curve(X, y):\n",
    "    clf=ske.RandomForestClassifier(n_estimators = 50)\n",
    "    parameter_grid = np.array([1, 200, 400, 600, 800, 1000])\n",
    "    train_size, train_scores, validation_scores = learning_curve(clf, X, y, train_sizes=parameter_grid, cv=5)\n",
    "    \n",
    "    # plot the data\n",
    "    plt.figure(figsize=(12, 8), dpi = 300)\n",
    "    plt.plot(parameter_grid, 100 * np.average(train_scores, axis=1), color='black',label='train accuracy')\n",
    "    plt.plot(parameter_grid, 100 * np.average(validation_scores,axis=1),color='red',label='validation accuracy')\n",
    "    plt.plot(parameter_grid,100*np.repeat((np.average(validation_scores,axis=1)[-1]+np.average(train_scores, axis=1)[-1])/2,6),\n",
    "             color='blue',linestyle='--',label='desired accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Learning curve')\n",
    "    plt.xlabel('Number of training samples')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 110])\n",
    "plot_confusion_matrix\n",
    "def plot_confusion_matrix(cm, labels_name, title):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]    # Normalize\n",
    "    plt.figure(figsize = (12, 8), dpi = 300)\n",
    "    plt.imshow(cm, interpolation='nearest')    # Display images on specific windows\n",
    "    plt.title(title)    # Title of the image\n",
    "    plt.colorbar()\n",
    "    num_local = np.array(range(len(labels_name)))\n",
    "    plt.xticks(num_local, labels_name, rotation=90)    \n",
    "    plt.yticks(num_local, labels_name)    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "#plot_ROC_CURVE\n",
    "def plot_ROC_CURVE(y,Y):\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, threshold = roc_curve(y, Y)  # Calculate TPR and FPR\n",
    "    roc_auc = auc(fpr, tpr)  # calculate ROC\n",
    "\n",
    "    plt.figure(figsize = (12, 8), dpi = 300)\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw = lw, label='ROC curve (area = %0.2f)' % roc_auc)  # FPR as x，TPR as y\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "#plot_pca is used for plotting the explanined variance of componets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the explaned variance of componet\n",
    "def plot_pca(X):   \n",
    "    cov_mat = np.cov(X.T)\n",
    "    eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "    tot = sum(eigen_vals)\n",
    "    var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "    cum_var_exp = np.cumsum(var_exp)\n",
    "    plt.figure(figsize = (12, 8), dpi = 300)\n",
    "    plt.bar(range(1, 1+len(var_exp)), var_exp, alpha=0.5, align='center',label='individual explained variance')\n",
    "    plt.step(range(1, 1+len(var_exp)), cum_var_exp, where='mid',label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal component index')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.title('Explained variance of componets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
